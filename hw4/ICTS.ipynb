{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57959291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(tf.__version__)\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd8a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models,optimizers\n",
    "import os, sys\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad5c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file_dir=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\train\\img'\n",
    "lab_file_dir=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\train\\lab'\n",
    "\n",
    "IMG_SIZE=128\n",
    "\n",
    "def ReFileName(dirPath):\n",
    "    listdir=os.listdir(dirPath)\n",
    "    img_list=[]\n",
    "    for file in listdir:\n",
    "        if os.path.isfile(os.path.join(dirPath, file)) == True:\n",
    "            c= os.path.basename(file)\n",
    "            name = dirPath + '\\\\' + c\n",
    "            image=Image.open(name).resize((IMG_SIZE, IMG_SIZE))\n",
    "            img_list.append(np.asarray(image))\n",
    "    return img_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e84004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list=ReFileName(img_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5f762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_list=ReFileName(lab_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b1f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23512, 128, 128)\n",
      "(23512, 128, 128, 1)\n",
      "----------------\n",
      "(23512, 128, 128)\n",
      "(23512, 128, 128, 1)\n",
      "(16458, 128, 128, 1)\n",
      "(16458, 128, 128, 1)\n",
      "(7054, 128, 128, 1)\n",
      "(7054, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "image_numpy=np.asarray(img_list).astype('float32')/255.0\n",
    "print(image_numpy.shape)\n",
    "image_numpy=image_numpy.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "print(image_numpy.shape)\n",
    "print('----------------')\n",
    "lab_numpy=np.asarray(lab_list)\n",
    "print(lab_numpy.shape)\n",
    "lab_numpy=lab_numpy.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "print(lab_numpy.shape)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data, train_label, val_label = train_test_split(image_numpy, lab_numpy, test_size=0.3, random_state=0)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(val_data.shape)\n",
    "print(val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa92c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D\n",
    "def create_model(input_size = (512,512,1)):\n",
    "    l2 = tf.keras.regularizers.l2(0.01)\n",
    "    \n",
    "    inputs = layers.Input(input_size)\n",
    "    conv1 = layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = layers.Dropout(0.5)(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    \n",
    "    bn=layers.BatchNormalization()(pool4)\n",
    "    \n",
    "    conv5 = layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2 )(bn)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2)(conv5)\n",
    "    drop5 = layers.Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(layers.UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = layers.concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(layers.UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = layers.concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(layers.UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = layers.concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(layers.UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = layers.concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = layers.Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=conv10)\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723a4b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 16, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)    0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 8, 8, 512)    2048        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 1024)   4719616     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 1024)   9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 1024)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 16, 16, 1024) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 512)  2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 1024) 0           dropout[0][0]                    \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 128)  131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 2)  1154        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 1)  3           conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,033,733\n",
      "Trainable params: 31,032,709\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "U_model=create_model((IMG_SIZE,IMG_SIZE,1))\n",
    "\n",
    "metrics_list=[\n",
    "tf.keras.metrics.Precision(name='precision'),\n",
    "tf.keras.metrics.Recall(name='recall'),\n",
    "tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "tf.keras.metrics.FalseNegatives(name='FN'),\n",
    "tf.keras.metrics.FalsePositives(name='FP'),\n",
    "tf.keras.metrics.TrueNegatives(name='TN'),\n",
    "tf.keras.metrics.TruePositives(name='TP'),\n",
    "tf.keras.metrics.AUC(name='ROC'),\n",
    "]\n",
    "\n",
    "adam=tf.keras.optimizers.SGD(learning_rate=0.05,momentum=0.5)\n",
    "model_loss=tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "\n",
    "U_model.compile(optimizer=adam,\n",
    "              loss=model_loss,\n",
    "              metrics=metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76c2ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1029/1029 [==============================] - 179s 168ms/step - loss: 20.1075 - precision: 0.8952 - recall: 0.0321 - accuracy: 0.6577 - FN: 44303177.7544 - FP: 43851.9903 - TN: 89052944.6340 - TP: 1734838.0194 - ROC: 0.9196 - val_loss: 1.2586 - val_precision: 0.0484 - val_recall: 0.1836 - val_accuracy: 0.9794 - val_FN: 422486.0000 - val_FP: 1868349.0000 - val_TN: 113186776.0000 - val_TP: 95031.0000 - val_ROC: 0.8922\n",
      "INFO:tensorflow:Assets written to: C:/Users/User/Desktop/hong/ICTS\\unet_06\\assets\n",
      "Epoch 2/25\n",
      "1029/1029 [==============================] - 171s 166ms/step - loss: 0.4761 - precision: 1.0000 - recall: 0.0511 - accuracy: 0.6589 - FN: 43768592.0204 - FP: 0.0000e+00 - TN: 89014538.1282 - TP: 2351639.7689 - ROC: 0.9785 - val_loss: 0.5952 - val_precision: 0.0488 - val_recall: 0.1936 - val_accuracy: 0.9786 - val_FN: 417325.0000 - val_FP: 1954496.0000 - val_TN: 113100688.0000 - val_TP: 100192.0000 - val_ROC: 0.8918\n",
      "Epoch 3/25\n",
      "1029/1029 [==============================] - 170s 165ms/step - loss: 0.1599 - precision: 1.0000 - recall: 0.0508 - accuracy: 0.6586 - FN: 43790962.5282 - FP: 0.0000e+00 - TN: 89004616.7243 - TP: 2339245.8398 - ROC: 0.9807 - val_loss: 0.4589 - val_precision: 0.0420 - val_recall: 0.2500 - val_accuracy: 0.9700 - val_FN: 388136.0000 - val_FP: 2950430.0000 - val_TN: 112104792.0000 - val_TP: 129381.0000 - val_ROC: 0.8926\n",
      "INFO:tensorflow:Assets written to: C:/Users/User/Desktop/hong/ICTS\\unet_06\\assets\n",
      "Epoch 4/25\n",
      "1029/1029 [==============================] - 169s 165ms/step - loss: 0.1548 - precision: 1.0000 - recall: 0.0497 - accuracy: 0.6583 - FN: 43825299.8437 - FP: 0.0000e+00 - TN: 89020876.7699 - TP: 2288561.6942 - ROC: 0.9826 - val_loss: 0.5931 - val_precision: 0.0496 - val_recall: 0.1889 - val_accuracy: 0.9793 - val_FN: 419767.0000 - val_FP: 1872583.0000 - val_TN: 113182608.0000 - val_TP: 97750.0000 - val_ROC: 0.8921\n",
      "Epoch 5/25\n",
      "1029/1029 [==============================] - 170s 165ms/step - loss: 0.1553 - precision: 1.0000 - recall: 0.0490 - accuracy: 0.6579 - FN: 43897072.9476 - FP: 0.0000e+00 - TN: 88978753.8641 - TP: 2259006.6485 - ROC: 0.9837 - val_loss: 0.5983 - val_precision: 0.0501 - val_recall: 0.1870 - val_accuracy: 0.9796 - val_FN: 420746.0000 - val_FP: 1834974.0000 - val_TN: 113220280.0000 - val_TP: 96771.0000 - val_ROC: 0.8923\n",
      "Epoch 6/25\n",
      "1029/1029 [==============================] - 171s 166ms/step - loss: 0.1540 - precision: 1.0000 - recall: 0.0486 - accuracy: 0.6597 - FN: 43834083.5146 - FP: 0.0000e+00 - TN: 89055085.3408 - TP: 2245653.8748 - ROC: 0.9846 - val_loss: 0.5923 - val_precision: 0.0500 - val_recall: 0.1882 - val_accuracy: 0.9795 - val_FN: 420103.0000 - val_FP: 1851960.0000 - val_TN: 113203280.0000 - val_TP: 97414.0000 - val_ROC: 0.8923\n",
      "Epoch 7/25\n",
      "1029/1029 [==============================] - 171s 167ms/step - loss: 0.1546 - precision: 1.0000 - recall: 0.0488 - accuracy: 0.6588 - FN: 43863189.6136 - FP: 0.0000e+00 - TN: 89034975.6689 - TP: 2236613.7738 - ROC: 0.9853 - val_loss: 0.5896 - val_precision: 0.0497 - val_recall: 0.1895 - val_accuracy: 0.9793 - val_FN: 419463.0000 - val_FP: 1873506.0000 - val_TN: 113181712.0000 - val_TP: 98054.0000 - val_ROC: 0.8923\n",
      "Epoch 8/25\n",
      "1029/1029 [==============================] - 172s 167ms/step - loss: 0.1544 - precision: 1.0000 - recall: 0.0485 - accuracy: 0.6589 - FN: 43841008.2107 - FP: 0.0000e+00 - TN: 89062227.2485 - TP: 2231478.6058 - ROC: 0.9858 - val_loss: 0.6124 - val_precision: 0.0507 - val_recall: 0.1802 - val_accuracy: 0.9804 - val_FN: 424252.0000 - val_FP: 1748050.0000 - val_TN: 113307168.0000 - val_TP: 93265.0000 - val_ROC: 0.8921\n",
      "Epoch 9/25\n",
      "1029/1029 [==============================] - 173s 168ms/step - loss: 0.1542 - precision: 1.0000 - recall: 0.0483 - accuracy: 0.6592 - FN: 43856324.9854 - FP: 0.0000e+00 - TN: 89048413.6408 - TP: 2230075.4689 - ROC: 0.9864 - val_loss: 0.6109 - val_precision: 0.0504 - val_recall: 0.1794 - val_accuracy: 0.9804 - val_FN: 424655.0000 - val_FP: 1749483.0000 - val_TN: 113305728.0000 - val_TP: 92862.0000 - val_ROC: 0.8920\n",
      "Epoch 10/25\n",
      "1029/1029 [==============================] - 174s 169ms/step - loss: 0.1533 - precision: 1.0000 - recall: 0.0474 - accuracy: 0.6603 - FN: 43833727.9670 - FP: 0.0000e+00 - TN: 89097242.5563 - TP: 2203802.9757 - ROC: 0.9867 - val_loss: 0.5875 - val_precision: 0.0494 - val_recall: 0.1894 - val_accuracy: 0.9792 - val_FN: 419525.0000 - val_FP: 1884033.0000 - val_TN: 113171192.0000 - val_TP: 97992.0000 - val_ROC: 0.8920\n",
      "Epoch 11/25\n",
      "1029/1029 [==============================] - 176s 171ms/step - loss: 0.1539 - precision: 1.0000 - recall: 0.0488 - accuracy: 0.6598 - FN: 43785423.0592 - FP: 0.0000e+00 - TN: 89112186.3621 - TP: 2237202.4942 - ROC: 0.9872 - val_loss: 0.6000 - val_precision: 0.0500 - val_recall: 0.1848 - val_accuracy: 0.9798 - val_FN: 421872.0000 - val_FP: 1817138.0000 - val_TN: 113238048.0000 - val_TP: 95645.0000 - val_ROC: 0.8919\n",
      "Epoch 12/25\n",
      "1029/1029 [==============================] - 176s 171ms/step - loss: 0.1541 - precision: 1.0000 - recall: 0.0480 - accuracy: 0.6588 - FN: 43870457.9233 - FP: 0.0000e+00 - TN: 89046951.4417 - TP: 2217372.1485 - ROC: 0.9874 - val_loss: 0.5786 - val_precision: 0.0491 - val_recall: 0.1935 - val_accuracy: 0.9787 - val_FN: 417373.0000 - val_FP: 1941366.0000 - val_TN: 113113888.0000 - val_TP: 100144.0000 - val_ROC: 0.8920\n",
      "Epoch 13/25\n",
      "1029/1029 [==============================] - 177s 172ms/step - loss: 0.1544 - precision: 1.0000 - recall: 0.0481 - accuracy: 0.6580 - FN: 43979259.3359 - FP: 0.0000e+00 - TN: 88933492.1573 - TP: 2221959.6845 - ROC: 0.9879 - val_loss: 0.6000 - val_precision: 0.0498 - val_recall: 0.1837 - val_accuracy: 0.9798 - val_FN: 422467.0000 - val_FP: 1814889.0000 - val_TN: 113240328.0000 - val_TP: 95050.0000 - val_ROC: 0.8918\n",
      "Epoch 14/25\n",
      "1029/1029 [==============================] - ETA: 0s - loss: 0.1545 - precision: 1.0000 - recall: 0.0480 - accuracy: 0.6585 - FN: 43868299.8785 - FP: 0.0000e+00 - TN: 88921533.9135 - TP: 2214228.7920 - ROC: 0.9882- ETA: 8s - loss: 0.1546 - precision: 1.0000 - recall: 0.0480 - accuracy: 0.6585 - FN: 41528868.3275 - FP: 0.0000e+"
     ]
    }
   ],
   "source": [
    "# train_data, val_data, train_data, val_label \n",
    "\n",
    "callbacks_list=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "          monitor='val_precision',mode='max', patience=10 ,restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='C:/Users/User/Desktop/hong/ICTS/unet_06',\n",
    "            monitor='val_precision',\n",
    "            save_best_only=True,\n",
    "        )\n",
    "       ]\n",
    "\n",
    "\n",
    "history=U_model.fit(train_data,train_data,\n",
    "                    validation_data=(val_data,val_label),\n",
    "                    epochs=25,\n",
    "                    batch_size=16,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ed0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_model.save('unet_06.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c4fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c2bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_history_graphic( history       # 資料集合\n",
    "                         , history_key1  # 資料集合裡面的來源 1 (有 loss, acc, val_loss, val_acc 四種)\n",
    "                         , history_key2  # 資料集合裡面的來源 2 (有 loss, acc, val_loss, val_acc 四種)\n",
    "                         , y_label       # Y 軸標籤文字\n",
    "                         , index=0\n",
    "                         ) :\n",
    "    plt.figure(figsize=(9,9))\n",
    "    font_size=20\n",
    "    # 資料來源 1\n",
    "    plt.plot( history.history[history_key1][index:] )\n",
    "    # 資料來源 2\n",
    "    plt.plot( history.history[history_key2][index:] )\n",
    "    # 標題\n",
    "    plt.title( 'train history',fontsize=font_size )\n",
    "    # X 軸標籤文字\n",
    "    plt.xlabel( 'epochs',fontsize=font_size )\n",
    "    # Y 軸標籤文字\n",
    "    plt.ylabel( y_label,fontsize=font_size )\n",
    "    plt.xticks(fontsize=font_size)\n",
    "    plt.yticks(fontsize=font_size)\n",
    "    \n",
    "    # 設定圖例\n",
    "    # (參數 1 為圖例說明, 有幾個資料來源, 就對應幾個圖例說明)\n",
    "    # (參數 2 為圖例位置, upper 為上面, lower 為下面, left 為左邊, right 為右邊)\n",
    "    if 'loss' is history_key1:\n",
    "        plt.legend( ['train', 'validate']\n",
    "               , loc = 'upper right'\n",
    "                ,fontsize=font_size)\n",
    "    else :\n",
    "        plt.legend( ['train', 'validate']\n",
    "       , loc = 'lower right'\n",
    "        ,fontsize=font_size)\n",
    "    # 顯示畫布 filename\n",
    "#     plot.savefig(r'D:\\_YUN\\26_DecisionAnalysis\\A0510\\ECG\\img\\{}_{}.png'.format(filename,history_key1))\n",
    "    plt.show()\n",
    "\n",
    "#############################################\n",
    "    \n",
    "metrics_name_list=['loss','precision','recall','accuracy']\n",
    "for metrics in metrics_name_list :\n",
    "  train_history_graphic( history, metrics, f'val_{metrics}', metrics, 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ec6ee",
   "metadata": {},
   "source": [
    "# load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "IMG_SIZE=128\n",
    "model_name='unet_02'\n",
    "test_model = keras.models.load_model(r'C:\\Users\\User\\Desktop\\hong\\ICTS\\{}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ece07b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 建立 預測存放 predict檔案 的資料夾\n",
    "\n",
    "\n",
    "dt = datetime.now().strftime('%m%d%H%M')\n",
    "predict_dir=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\{}_predict{}'.format(model_name,dt)\n",
    "if not os.path.isdir(predict_dir):\n",
    "    os.mkdir(predict_dir)\n",
    "\n",
    "def predict_arrays(img_fdata):\n",
    "#     print('----resize 至128*128-----')    \n",
    "#     print(img_fdata.shape)\n",
    "    \n",
    "    img_list=[]\n",
    "    for img in range(img_fdata.shape[0]):\n",
    "        img_list.append(np.asarray(Image.fromarray(np.uint8(img_fdata[img])).resize((IMG_SIZE,IMG_SIZE))))\n",
    "                        \n",
    "    img_arr=np.asarray(img_list).astype('float32')/255.0\n",
    "    img_arr=img_arr.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "#     print('依次預測個檔案的結果  img_arr(86,128,128,1) 或是 img_arr(76,128,128,1')\n",
    "    y_pred=test_model.predict(img_arr)\n",
    "    \n",
    "#   大於 0.5 機率值 =1 ，其他為0\n",
    "    y_pred=np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "#     print('----resize 回原來大小-----')   \n",
    "    y_pred_list=[]\n",
    "    for img in range(y_pred.shape[0]):\n",
    "        temp=np.uint8(y_pred[img])\n",
    "        temp=temp.reshape(IMG_SIZE,IMG_SIZE)\n",
    "        re_img=Image.fromarray(temp).resize((img_fdata.shape[1],img_fdata.shape[1]))\n",
    "        \n",
    "        y_pred_list.append(np.asarray(re_img))\n",
    "    \n",
    "    y_pred_list_arr=np.asarray(y_pred_list)\n",
    "#     print(y_pred.shape)\n",
    "#     print(y_pred_list_arr.shape)\n",
    "    return y_pred_list_arr # 反回一個 nii.gz 檔案的預測label\n",
    "\n",
    "################# \n",
    "# 1.讀取 nii 文件\n",
    "# 2.取得 Image array\n",
    "# 3. 調換 array 維度\n",
    "# 4. 預測一組 nii  predict_arrays ；產生預測arrays的方法\n",
    "# 5. 還原 array 維度\n",
    "# 6. 生成 Nifti1Image 物件\n",
    "# 7. 儲存 Nifti1Image\n",
    "####################\n",
    "# 8.將 1~7 的所有檔案壓縮\n",
    "\n",
    "\n",
    "# 讀取 並產生 nii.gz 檔案\n",
    "def re_test_flie(dirPath):\n",
    "    filenames = os.listdir(dirPath)  #讀取 nii 資料夹\n",
    "    slice_trans = []\n",
    " \n",
    "    for f in filenames:\n",
    "        # 讀取 nii 文件\n",
    "        img_path = os.path.join(dirPath, f)\n",
    "        img = nib.load(img_path)                #讀取 nii 文件\n",
    "        img_fdata = img.get_fdata()\n",
    "        \n",
    "#         print('img_fdata shape',img_fdata.shape)\n",
    "        \n",
    "        img_fdata=img_fdata.transpose((2,1,0))\n",
    "        \n",
    "#         print('img_fdata shape',img_fdata.shape)\n",
    "        \n",
    "        predict_data=predict_arrays(img_fdata[:,:,:])\n",
    "        \n",
    "        \n",
    "        predict_data=predict_data.transpose((2,1,0))\n",
    "        new_image = nib.Nifti1Image(predict_data, affine=img.affine)\n",
    "\n",
    "#         print(predict_file)\n",
    "\n",
    "        predict_file=r'{}\\{}'.format(predict_dir,f)\n",
    "#         print(predict_file)\n",
    "        nib.nifti1.save(new_image, predict_file)\n",
    "    \n",
    "#   zip 檔案\n",
    "    zip_file = predict_dir+'.zip'\n",
    "    if not os.path.exists(predict_dir):                # 如果目录路径不存在\n",
    "        print('目录不存在')\n",
    "    else:                                           # 否则压缩目录\n",
    "        zip = zipfile.ZipFile(zip_file, mode='w', compression=zipfile.ZIP_DEFLATED)\n",
    "        for item in os.listdir(predict_dir):\n",
    "            new_file_path = os.path.join(predict_dir,item)\n",
    "            zip.write(new_file_path,item)\n",
    "        zip.close()\n",
    "        \n",
    "        \n",
    "test_file_dir=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\image'\n",
    "re_test_flie(test_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\predict06171335\\2JA4PBWY.nii.gz')                #讀取 nii 文件\n",
    "img_fdata = img.get_fdata()\n",
    "set(img_fdata.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90eab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\predict06170307\\2JA4PBWY.nii.gz')                #讀取 nii 文件\n",
    "img_fdata = img.get_fdata()\n",
    "set(img_fdata.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386c291",
   "metadata": {},
   "source": [
    "# 測試功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6185cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file = r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\predict06161801.zip'\n",
    "if not os.path.exists(predict_dir):                # 如果目录路径不存在\n",
    "    print('目录不存在')\n",
    "else:                                           # 否则压缩目录\n",
    "    zip = zipfile.ZipFile(zip_file, mode='w', compression=zipfile.ZIP_DEFLATED)\n",
    "    for item in os.listdir(predict_dir):\n",
    "        new_file_path = os.path.join(predict_dir,item)\n",
    "        zip.write(new_file_path,item)\n",
    "    zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713eb32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 檢視 affine \n",
    "\n",
    "file_2JA4PBWY=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\image\\2JA4PBWY.nii.gz'\n",
    "file_2JA4PBWY=nib.load(file_2JA4PBWY)\n",
    "print(file_2JA4PBWY.affine)\n",
    "print(file_2JA4PBWY.get_fdata().shape)\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "img_2JA4PBWY=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\predict06170259\\2JA4PBWY.nii.gz'\n",
    "img_2JA4PBWY=nib.load(img_2JA4PBWY)\n",
    "# temp_data=file_2ABGOEM3.get_fdata()\n",
    "print(img_2JA4PBWY.affine)\n",
    "print(img_2JA4PBWY.get_fdata().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af26fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def nii_to_image(dirPath):\n",
    "    filenames = os.listdir(dirPath)  #读取nii文件夹\n",
    "    slice_trans = []\n",
    " \n",
    "    for f in filenames:\n",
    "        #开始读取nii文件\n",
    "        img_path = os.path.join(dirPath, f)\n",
    "        img = nib.load(img_path)                #读取nii\n",
    "        img_fdata = img.get_fdata()\n",
    "        img_fdata=img_fdata.transpose((2,1,0))\n",
    "        fname = f.replace('.nii.gz','')            #去掉nii的后缀名\n",
    "\n",
    "        print(img_fdata.shape)\n",
    "\n",
    "\n",
    "label_file_name=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\label'\n",
    "nii_to_image(label_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a3e7f",
   "metadata": {},
   "source": [
    "# nii convert png and move file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ea16c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os                #遍历文件夹\n",
    "import nibabel as nib    #nii格式一般都会用到这个包\n",
    "import imageio           #转换成图像\n",
    " \n",
    "def nii_to_image(dirPath,outdir):\n",
    "    filenames = os.listdir(dirPath)  #读取nii文件夹\n",
    "    slice_trans = []\n",
    " \n",
    "    for f in filenames:\n",
    "        #开始读取nii文件\n",
    "        img_path = os.path.join(dirPath, f)\n",
    "        img = nib.load(img_path)                #读取nii\n",
    "        img_fdata = img.get_fdata()\n",
    "        img_fdata=img_fdata.transpose((2,1,0))\n",
    "        fname = f.replace('.nii.gz','')            #去掉nii的后缀名\n",
    "        img_f_path = os.path.join(outdir)\n",
    "#         print(img_fdata.shape)\n",
    "#         print(img_path)\n",
    "#         print(img_f_path)\n",
    "#         i=0\n",
    "#         print(os.path.join(img_f_path,'{}_{}.png'.format(fname,i)))\n",
    "        #开始转换为图像\n",
    "        (x,y,z) = img_fdata.shape\n",
    "        for i in range(0,x,1):                      #z是图像的序列\n",
    "            silce = img_fdata[i, :, :]          #选择哪个方向的切片都可以\n",
    "            imageio.imwrite(os.path.join(img_f_path,'{}_{}.png'.format(fname,i)), silce)\n",
    "            \n",
    "image_file_name=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\image'\n",
    "image_file_out=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\img'\n",
    "nii_to_image(image_file_name,image_file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9e480",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_file_name=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\label'\n",
    "label_file_out=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\lab'\n",
    "nii_to_image(label_file_name,label_file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45eaa0d",
   "metadata": {},
   "source": [
    "# ICTS-test-2020 convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c7ce4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_file_name=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\image'\n",
    "test_file_out=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\ICTS-test-2020\\img'\n",
    "nii_to_image(test_file_name,test_file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e62ed",
   "metadata": {},
   "source": [
    "# 複製到 train  lab 目錄下 有白色目標的 png ，對應 train img 目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "img_file_dir=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\img'\n",
    "lab_file_dir=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\lab'\n",
    "\n",
    "img_train_dir=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\train\\img'\n",
    "lab_train_dir=r'C:\\Users\\User\\Desktop\\hong\\ICTS\\train\\lab'\n",
    "\n",
    "def ReFileName(dirPath):\n",
    "    listdir=os.listdir(dirPath)\n",
    "    for file in listdir:\n",
    "        if os.path.isfile(os.path.join(dirPath, file)) == True:\n",
    "            c= os.path.basename(file)\n",
    "            name = dirPath + '\\\\' + c\n",
    "            image=Image.open(name)\n",
    "            image_arr=np.asarray(image)\n",
    "            image_arr=image_arr.flatten()\n",
    "            \n",
    "            \n",
    "            img_name=name.replace('\\\\lab\\\\','\\\\img\\\\')\n",
    "            target_lab=name.replace('\\\\lab\\\\','\\\\train\\\\lab\\\\')\n",
    "            target_img=name.replace('\\\\lab\\\\','\\\\train\\\\img\\\\')\n",
    "#             print(name )\n",
    "#             print(img_name)    \n",
    "#             print (target_lab)   \n",
    "#             print  (target_img)  \n",
    "           \n",
    "            \n",
    "            if len(set(image_arr))>1:\n",
    "                shutil.copy(name,target_lab) \n",
    "                shutil.copy(img_name,target_img) \n",
    "#                 print(img_name)\n",
    "#                 print(name)    \n",
    "#                 os.remove(img_name)\n",
    "#                 os.remove(name)\n",
    "#                 print(set(image_arr))\n",
    "#                 print(len(set(image_arr)))\n",
    "#                 print('---------------------------')\n",
    "\n",
    "# ReFileName(lab_file_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
