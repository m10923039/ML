{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "'''gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0' '''\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import * \n",
    "import time\n",
    "\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "t=time.time()\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    tf.random.set_seed(0)\n",
    "    a = tf.random.uniform((10000,10000),minval = 0,maxval = 3.0)\n",
    "    c = tf.matmul(a, tf.transpose(a))\n",
    "    d = tf.reduce_sum(c)\n",
    "print('gpu: ', time.time()-t)\n",
    "\n",
    "t=time.time()\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    tf.random.set_seed(0)\n",
    "    a = tf.random.uniform((10000,10000),minval = 0,maxval = 3.0)\n",
    "    c = tf.matmul(a, tf.transpose(a))\n",
    "    d = tf.reduce_sum(c)\n",
    "print('cpu: ', time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAR train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ho\n",
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models,optimizers\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "img_resize=(224,224)\n",
    "def ReFileName(dirPath):\n",
    "    mango=[]\n",
    "    for file in os.listdir(dirPath):\n",
    "        if os.path.isfile(os.path.join(dirPath, file)) == True:\n",
    "           c= os.path.basename(file)\n",
    "           name = dirPath + '\\\\' + c\n",
    "           img = cv2.imread(name)\n",
    "           img=cv2.resize(img,img_resize)\n",
    "           mango.append(img)\n",
    "    return mango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ce403f55f0d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmango\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReFileName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmango\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-def09dcbcb84>\u001b[0m in \u001b[0;36mReFileName\u001b[1;34m(dirPath)\u001b[0m\n\u001b[0;32m     23\u001b[0m            \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirPath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m            \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m            \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_resize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m            \u001b[0mmango\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmango\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#圖片路徑\n",
    "\n",
    "# train_dir = r'C:\\Users\\lab543\\Desktop\\DATA\\Train_Image'\n",
    "# dirPath = r\"C:\\Users\\lab543\\Desktop\\DATA\\Train_Image\"\n",
    "# valid_dir  = r'C:\\Users\\lab543\\Desktop\\DATA\\Test_Image'\n",
    "\n",
    "\n",
    "train_dir = r'D:\\_YUN\\24_ML\\Work02\\Mango\\DATA'\n",
    "dirPath =train_dir+ r'\\Train_Image_512'\n",
    "\n",
    "\n",
    "#標籤路徑\n",
    "train_label = pd.read_csv(train_dir+ r'\\train.csv',header = 0)\n",
    "\n",
    "#One-hot\n",
    "train_label = train_label['label'].map({\"A\":0, \"B\":1,\"C\":2})\n",
    "train_label = to_categorical(train_label)\n",
    "\n",
    "mango = ReFileName(dirPath)\n",
    "datas=np.array(mango).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset = <BatchDataset shapes: ((None, 224, 224, 3), (None, 3)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#切割\n",
    "train_data, val_data, train_label, val_label = train_test_split(datas, train_label, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "tensor_train_data=tf.constant(train_data)\n",
    "tensor_train_label=tf.constant(train_label,dtype=tf.int32)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((tensor_train_data, tensor_train_label))\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "print( 'train_dataset =', train_dataset )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ho\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "def create_model():\n",
    "    net = VGG16(include_top=False, weights='imagenet', input_tensor=None,\n",
    "          input_shape = (train_data.shape[1],train_data.shape[2],train_data.shape[3])\n",
    "          )\n",
    "    l2 = tf.keras.regularizers.l2(0.01)\n",
    "\n",
    "    # 透過layer_name 節取 model的某一層 block3_pool block4_conv3\n",
    "    layer_name='block4_pool'\n",
    "\n",
    "    # 設定取到該層的都使用預設參數，不訓練參數\n",
    "    layer_index=net.layers.index(net.get_layer(layer_name))\n",
    "\n",
    "    # 建立模型\n",
    "    base_model = net.get_layer(layer_name).output\n",
    "    base_model = layers.Conv2D(128, (1, 1), padding='valid')(base_model)\n",
    "    base_model = layers.MaxPooling2D( pool_size = (3, 3) )(base_model)\n",
    "\n",
    "    # 攤平 feature map \n",
    "    base_model = layers.Flatten()(base_model)\n",
    "\n",
    "\n",
    "    base_model = layers.Dropout(0.3)(base_model)\n",
    "    base_model = layers.BatchNormalization()(base_model)\n",
    "    base_model = layers.Dense(units = 256, kernel_initializer = tf.keras.initializers.GlorotNormal()\n",
    "             ,kernel_regularizer= l2 , activation= 'relu')(base_model)\n",
    "\n",
    "\n",
    "    base_model = layers.Dense(units = 256, kernel_initializer = tf.keras.initializers.GlorotNormal()\n",
    "             ,kernel_regularizer = l2 , activation= 'relu')(base_model)\n",
    "\n",
    "    base_model = layers.Dropout(0.3)(base_model)\n",
    "    output_layer = layers.Dense(train_label.shape[1], activation='softmax', name='softmax')(base_model)\n",
    "\n",
    "    # 設定凍結與要進行訓練的網路層\n",
    "    net_final = tf.keras.models.Model(inputs=net.input, outputs=output_layer)\n",
    "\n",
    "    for layer in net_final.layers[:layer_index]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return net_final\n",
    "\n",
    "test_model=create_model()\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  compile fit  callbacks 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ho\n",
    "\n",
    "# \n",
    "# Generate batches of tensor image data with real-time data augmentation.\n",
    "\n",
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=15 , \n",
    "                             width_shift_range=0.2 , \n",
    "                             height_shift_range=0.2 ,\n",
    "                             shear_range=0.2 ,\n",
    "                             zoom_range=0.2 , \n",
    "                             data_format='channels_last')\n",
    "\n",
    "callbacks_list=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "          monitor='val_loss',mode='min', patience=10 ,restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='C:/Users/lab543/Desktop/DATA/Mango01.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',\n",
    "                             patience=3,\n",
    "                             # 3 epochs 內acc沒下降就要調整LR\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             # LR降為0.5\n",
    "                             min_lr=0.00001\n",
    "                             # 最小 LR 到0.00001就不再下降\n",
    "                             )]\n",
    "\n",
    "precision=tf.keras.metrics.Precision(name='precision')\n",
    "recall=tf.keras.metrics.Recall(name='recall')\n",
    "accuracy=tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
    "\n",
    "\n",
    "test_model.compile(optimizer='Adam' , loss='categorical_crossentropy' , metrics=[precision,recall,accuracy])\n",
    "history=test_model.fit(train_datagen.flow(train_data,train_label,batch_size=256),\n",
    "                       epochs=30,\n",
    "                       validation_data=(val_data,val_label),\n",
    "                       callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   畫 train 圖  、評估測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HO\n",
    "import matplotlib.pyplot as plot  \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "def train_history_graphic( history       # 資料集合\n",
    "              , history_key1  # 資料集合裡面的來源 1 (有 loss, acc, val_loss, val_acc 四種)\n",
    "              , history_key2  # 資料集合裡面的來源 2 (有 loss, acc, val_loss, val_acc 四種)\n",
    "              , y_label       # Y 軸標籤文字\n",
    "                         ) :\n",
    "    # 資料來源 1\n",
    "    plot.plot( history.history[history_key1] )\n",
    "    # 資料來源 2\n",
    "    plot.plot( history.history[history_key2] )\n",
    "    # 標題\n",
    "    plot.title( 'train history' )\n",
    "\n",
    "    # X 軸標籤文字\n",
    "    plot.xlabel( 'epochs' )\n",
    "\n",
    "    # Y 軸標籤文字\n",
    "    plot.ylabel( y_label )\n",
    "\n",
    "    # 設定圖例\n",
    "    # (參數 1 為圖例說明, 有幾個資料來源, 就對應幾個圖例說明)\n",
    "    # (參數 2 為圖例位置, upper 為上面, lower 為下面, left 為左邊, right 為右邊)\n",
    "    plot.legend( ['train', 'validate']\n",
    "               , loc = 'upper left'\n",
    "               )\n",
    "\n",
    "    # 顯示畫布\n",
    "    plot.show()\n",
    "\n",
    "# train_history_graphic( history, 'loss', 'val_loss', 'loss' )\n",
    "# train_history_graphic( history, 'accuracy', 'val_accuracy', 'accuracy' )\n",
    "# train_history_graphic( history, 'precision', 'val_precision', 'precision' )\n",
    "# train_history_graphic( history, 'recall', 'val_recall', 'recall' )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 顯示 Model 評估測試資料的\n",
    "preds=test_model.evaluate(test_data,test_label)\n",
    "\n",
    "print('loss ： %.5f' % preds[0])\n",
    "print('precision：%.5f' % preds[1])\n",
    "print('recall：%.5f' % preds[2])\n",
    "print('accuracy： %.5f' % preds[3])\n",
    "F1 = 2 * (preds[3] * preds[2]) / (preds[3] + preds[2])\n",
    "print('f1score：%.5f' % F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_model 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021-04-23 load_model\n",
    "\n",
    "test_model = keras.models.load_model('Mango01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TestdirPath = r\"D:\\_YUN\\24_ML\\Work02\\Mango\\DATA\\Test_Image\"\n",
    "Testmango = ReFileName(TestdirPath)\n",
    "\n",
    "#標籤路徑\n",
    "test_label = pd.read_csv(r'D:\\_YUN\\24_ML\\Work02\\Mango\\DATA\\test.csv',header = 0)\n",
    "\n",
    "#One-hot\n",
    "test_label = test_label['label'].map({\"A\":0, \"B\":1,\"C\":2})\n",
    "test_label = to_categorical(test_label)\n",
    "\n",
    "test_data=np.array(Testmango).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data = (250, 224, 224, 3)\n",
      "test_label = (250, 3)\n"
     ]
    }
   ],
   "source": [
    "print( 'test_data =', test_data.shape )\n",
    "print( 'test_label =', test_label.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "tensor_test_data=tf.constant(test_data)\n",
    "tensor_test_label=tf.constant(test_label)\n",
    "# test_dataset = tf.data.Dataset.from_tensors((tensor_test_data, tensor_test_label))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((tensor_test_data, tensor_test_label))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 45s 20s/step - loss: 0.6718 - precision: 0.7806 - recall: 0.7400 - accuracy: 0.7800\n",
      "loss ： 0.67181\n",
      "precision：0.78059\n",
      "recall：0.74000\n",
      "accuracy： 0.78000\n",
      "f1score：0.75947\n"
     ]
    }
   ],
   "source": [
    "# 顯示 Model 評估測試資料的\n",
    "preds=test_model.evaluate(test_dataset)\n",
    "\n",
    "print('loss ： %.5f' % preds[0])\n",
    "print('precision：%.5f' % preds[1])\n",
    "print('recall：%.5f' % preds[2])\n",
    "print('accuracy： %.5f' % preds[3])\n",
    "F1 = 2 * (preds[3] * preds[2]) / (preds[3] + preds[2])\n",
    "print('f1score：%.5f' % F1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "0318Churn",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
